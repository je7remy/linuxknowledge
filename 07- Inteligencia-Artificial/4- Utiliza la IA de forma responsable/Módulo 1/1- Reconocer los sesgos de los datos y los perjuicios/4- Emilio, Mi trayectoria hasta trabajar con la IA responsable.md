
### IA para el bienestar social

Hola, soy **Emilio**. Trabajo en **Google** y soy **gerente del Programa de Innovación Responsable**.  
Siempre me preguntan:

> “Espera, ¿entonces eras licenciado en Ciencias Políticas y en Español, y ahora trabajas en IA? ¿Qué haces exactamente?”

Mi mejor respuesta es que hago **de todo y nada a la vez**.  
Como gerente de programa, me aseguro de que las cosas se hagan a tiempo, de que las personas trabajen en conjunto y colaboren de manera eficiente. Conecto a los **expertos en IA** —especialistas en áreas como la percepción o la equidad— con los **equipos de desarrollo de productos** que buscan incorporar esas prácticas recomendadas.

Leí un libro muy impactante sobre los **peligros de automatizar ciertos niveles de desigualdad sistémica**, y eso realmente me abrió los ojos. No solo me hizo reflexionar sobre las posibilidades de la IA —porque me considero un **optimista tecnológico**—, sino también sobre las **ramificaciones** de aplicar IA sin enseñar completamente a las personas, ni comprender nosotros mismos, quienes la implementamos, cuáles son las consecuencias de estos sistemas.

Al pensar en nuestros propios antecedentes, educación y cultura, cada uno tiene un conjunto de experiencias que define quién es, y que sirve de base para sus valores y creencias fundamentales.  
Lo mismo ocurre con la IA.

Por ejemplo, yo soy del **sur de California**. Tengo predilección por el sol y las olas perfectas. Tal vez muchas personas también, pero en mi caso es algo muy propio.  
Estos aspectos humanos no siempre son directamente traducibles a un modelo de aprendizaje automático. Sin embargo, dado que las **experiencias pueden equipararse con datos**, los modelos de IA solo pueden aprender de los datos que se les proporcionan, ya sea a través de **conjuntos históricos** o de **comentarios de usuarios**.

Si logramos que estos sistemas representen mejor a los usuarios a quienes pretenden servir, creo que podremos **ayudar a más personas**.  
Muchas veces me pregunto:

> ¿Qué información integra esos conjuntos de datos?  
> ¿A quién se incluye y a quién se excluye?

Un ejemplo que considero mucho son los **sistemas de detección facial** y las **redes sociales**.  
Me cuestiono:

> ¿Qué tan bien funcionan esos sistemas para las personas que se parecen a mí, que tenemos una piel más rica en melanina?  
> ¿Funcionan de manera igualitaria en todo el espectro?

Creo que todos tenemos una **responsabilidad personal** al utilizar estas herramientas.  
Hay dos cosas fundamentales que podemos hacer:

1. **Comprobar los resultados** de la herramienta que estemos usando.
    
2. Si vas a incorporar nuevos datos al modelo, **verifica esos datos**: asegúrate de que sean inclusivos y representativos de las diversas comunidades con las que esperas interactuar.
    

Finalmente, **involúcrate**.  
Da retroalimentación constante sobre lo que apruebas o desapruebas, para que los equipos que crean estos sistemas sepan **cómo mejorar**.

---
