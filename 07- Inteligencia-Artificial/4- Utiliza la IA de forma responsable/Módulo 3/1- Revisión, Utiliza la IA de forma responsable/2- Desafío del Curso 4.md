
# 1 — Promotor de viviendas asequibles (elige 3)

**Respuestas seleccionadas:**

- **Revelando a sus clientes cómo utiliza la IA.**  
    _Justificación:_ La transparencia permite que los clientes comprendan decisiones (p. ej. diseño, coste, criterios) y evalúen riesgos/beneficios. También facilita la rendición de cuentas y construye confianza ética y legal.
    
- **Mediante el uso de diversos conjuntos de entrenamiento para mitigar el sesgo en los modelos de IA.**  
    _Justificación:_ Conjuntos de datos diversos reducen la probabilidad de que el modelo reproduzca desigualdades (por ejemplo, diseños que excluyan necesidades de ciertos grupos). Esto mejora equidad en resultados y evita decisiones discriminatorias.
    
- **Tomando medidas para proteger la privacidad y la seguridad de los datos de sus clientes.**  
    _Justificación:_ Los diseños podrían usar datos personales (hábitos, ingresos, preferencias). Protección de datos (minimización, cifrado, control de acceso) es imprescindible para cumplir leyes y mantener la confianza.
    

**Por qué no elegir:**

- _Desarrollando viviendas más rápidamente para beneficiar a sus acreedores._ Aunque velocidad puede ser deseable, priorizar solamente rapidez en beneficio de acreedores puede entrar en conflicto con el uso responsable de IA (p. ej. recortar pruebas, ignorar impactos sociales o seguridad). No es una medida de uso responsable.
    

---

# 2 — Denegación injusta de préstamos por barrio

**Respuesta seleccionada:** **Distributivo**  
_Justificación:_ El daño es «distributivo» porque afecta de forma desigual a un grupo geográfico o social (solicitantes de un barrio) — es un perjuicio en la distribución de beneficios/recursos (acceso al crédito). Se trata de un resultado sesgado que socialmente distribuye desventajas.

**Por qué no elegir las otras opciones:**

- _"Deepfakes":_ se refiere a falsificación multimedia; no aplica.
    
- _Representativo:_ normalmente describe sesgo en cómo se representan grupos en datos; aunque relacionado, la descripción del escenario es un efecto distributivo (resultados injustos), no sólo una mala representación en el set de datos.
    
- _Límite de conocimientos:_ se refiere a que el modelo no sabe algo fuera de su entrenamiento; aquí el problema es injusticia en decisiones, no falta de conocimiento.
    

---

# 3 — Herramienta de IA que responde de forma imprecisa tras funciones nuevas

**Respuesta seleccionada:** **Estancamiento**  
_Justificación:_ «Estancamiento» (staleness) describe cuando un modelo no ha sido actualizado con datos recientes o cambios de dominio y por tanto sus respuestas quedan desalineadas con la realidad actual (p. ej. nuevas funciones de la app). El modelo “se queda atrás” y emite respuestas incorrectas porque su conocimiento está desactualizado.

**Por qué no elegir las otras opciones:**

- _Ingeniería de instrucciones:_ refiere a cómo formular prompts para obtener mejores respuestas, no a falta de datos actualizados.
    
- _Incompetencia:_ es vaga; podría implicar mal rendimiento pero no especifica la causa (incompetencia humana o del modelo). El término técnico aquí es estancamiento por falta de actualización.
    
- _Desvío:_ suele referirse a comportamiento inesperado o que el modelo se desvía de la intención; no encaja tan bien como «estancamiento» cuando la causa es falta de datos recientes.
    

---

# 4 — Sesgo sistémico (elige 2)

**Respuestas seleccionadas:**

- **El sesgo sistémico es una tendencia que perdura por las instituciones que favorecen a determinados grupos.**  
    _Justificación:_ El sesgo sistémico está integrado en prácticas/instituciones (p. ej. políticas, normas, procedimientos) que reproducen ventajas para ciertos grupos.
    
- **El sesgo sistémico existe en los sistemas sociales, como la educación o la justicia penal.**  
    _Justificación:_ Es un fenómeno social e institucional — se observa en sistemas amplios (educación, salud, justicia) y no sólo en datos aislados.
    

**Por qué no elegir las otras opciones:**

- _El sesgo sistémico se produce cuando la precisión de las predicciones de un modelo de IA disminuye debido a los cambios en el tiempo._ Eso describe más bien **drift** o degradación por cambio de distribución, no lo que normalmente llamamos «sesgo sistémico».
    
- _El sesgo sistémico solo se refleja en los conjuntos de datos de mala calidad._ Incorrecto: puede originarse en prácticas sociales/instituciones y aparecer incluso si los datos técnicamente son «completos» pero reflejan desigualdades históricas. No es solo cuestión de calidad de datos.
    

---

# 5 — Contador usando software de IA (elige 3)

**Respuestas seleccionadas:**

- **Comprender las prácticas de recopilación de datos de la herramienta de IA.**  
    _Justificación:_ Saber qué datos recoge, con qué propósito y cuánto tiempo los retiene permite al contador proteger información sensible y cumplir normas (confidencialidad, requisitos regulatorios).
    
- **Familiarizarse con los nuevos avances en IA y sus riesgos asociados.**  
    _Justificación:_ Mantenerse actualizado ayuda a identificar vulnerabilidades, límites del sistema y prácticas recomendadas para mitigar riesgos (p. ej. fuga de datos, decisiones automatizadas incorrectas).
    
- **Leer las condiciones de uso o servicio de la herramienta de IA.**  
    _Justificación:_ Las condiciones indican responsabilidades, derechos sobre los datos, cláusulas sobre uso de datos de clientes y limitaciones legales; leerlas evita sorpresas y protege al cliente y al profesional.
    

**Por qué no elegir:**

- _Crear entradas exhaustivas incluyendo muchos detalles específicos y personalizados._ Esto es **precisamente lo contrario** de una buena práctica en muchos casos: aportar demasiada información sensible al software de IA (especialmente si procesa datos fuera del control del profesional) aumenta el riesgo de exposición. En vez de eso, se recomienda minimizar datos personales y sólo compartir lo necesario.
    

---

