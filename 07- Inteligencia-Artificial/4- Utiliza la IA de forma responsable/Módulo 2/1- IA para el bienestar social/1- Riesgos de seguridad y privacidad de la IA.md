
### Privacidad y seguridad en el uso responsable de la IA

Aprendiste que es importante ser **consciente de los posibles daños** que pueden generar las herramientas de inteligencia artificial (IA).  
Igualmente, es fundamental contar con los **conocimientos necesarios** para tomar decisiones informadas sobre los datos, especialmente en lo que respecta a la **privacidad** y la **seguridad**.

#### Privacidad

La **privacidad** es el derecho de una persona a tener control sobre cómo se recopila, almacena y utiliza su información personal.  
Los modelos de IA se entrenan utilizando diversos tipos de información, incluidos **conjuntos de datos** y **entradas de usuarios**.  
Por ejemplo, durante una interacción con una herramienta de IA, un usuario podría revelar información privada como:

- Nombres y direcciones
    
- Historial o registros médicos
    
- Información financiera o de pago
    

Si utilizas una herramienta de IA en tu trabajo, podrías incluir detalles específicos sobre un proyecto, las partes interesadas o los clientes para obtener resultados más precisos. Sin embargo, este tipo de uso puede **representar un riesgo para la seguridad**.

#### Seguridad

La **seguridad** consiste en proteger la información personal y los datos privados, garantizando que el sistema esté resguardado frente a accesos no autorizados.  
La mayoría de los líderes del sector tecnológico reconocen que la **IA generativa** puede introducir **nuevos riesgos de seguridad**, por lo que las organizaciones deben establecer **medidas de protección adecuadas** antes de implementarla.

Como usuario, también puedes tomar medidas para **proteger tu privacidad y seguridad**, así como la de tu organización, tus compañeros y socios comerciales. Entre ellas se incluyen:

1. **Revisar las condiciones de uso y políticas de privacidad** de cualquier herramienta de IA antes de utilizarla.  
    Comprueba qué tan transparente es respecto a la recopilación de datos y cómo los utiliza.
    
2. **Evitar ingresar información personal o confidencial.**  
    La mayoría de las herramientas de IA funcionan correctamente sin necesidad de datos personales.  
    Mantén en privado información como tu identidad, datos presupuestarios o dirección de correo electrónico.
    
3. **No compartir datos sensibles.**  
    Evita incluir información confidencial en una herramienta de IA para reducir el riesgo de filtraciones o violaciones de seguridad.  
    Si deseas personalizar resultados, puedes editar los detalles posteriormente.
    
4. **Confiar en herramientas con equipos sólidos de seguridad y privacidad.**  
    Las plataformas de IA responsables comunican de forma clara los riesgos y las medidas implementadas para mitigarlos.
    
5. **Mantenerse actualizado.**  
    La IA evoluciona constantemente, al igual que las estrategias de seguridad.  
    Lee con frecuencia **fuentes confiables**, **publicaciones académicas** y **opiniones de expertos** para estar al tanto de los últimos avances y riesgos emergentes.
    

---

En conclusión, la **privacidad y la seguridad** son pilares fundamentales del uso responsable de la inteligencia artificial.  
Saber cómo proteger tanto tu información como la de tu organización es una parte esencial de una **IA ética y segura**.

---

